{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d0c09f",
   "metadata": {},
   "source": [
    "# Eigene Sentiment Analysis mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde340a",
   "metadata": {},
   "source": [
    "Informationen:\n",
    "<h5>Dies ist die Ausarbeitung von <u>Nico Mirchandani</u> für das Modul Deep Learning</h5>\n",
    "Verlinkungen sind blau mit Unterstreichungen. Beispielsweise hier: <a href=\"https://www.python.org/>Ein Link zur Python Website</a>, die Programmiersprache, die ich hier verwenden werde.<br />\n",
    "Dinge die ich in Studien gefunden habe, werde ich normal zitieren.\n",
    "<br />\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bfbc05",
   "metadata": {},
   "source": [
    "Dies ist mein (<i>Nico Mirchandani</i>) Versuch ein Deep Learning Model von Beginn an selbst zu schreiben. \n",
    "Was benötigt wird: \n",
    "<ol>\n",
    "    <li>Preprocessing</li>\n",
    "    <li>Lernmodell, welches am Ende eine Prediction machen kann, wie positiv/negativ/neutral ein Wort ist. Dies sollte ein Wert zwischen -1 und 1 werden</li>\n",
    "    <li>Speicherung der vom Model gelernten Dinge, um nicht jedes mal von vorne das Training zu beginnen</li>\n",
    "</ol>\n",
    "Am Ende wird das Modell mit anderen Modellen verglichen: Modell welches importiert wird <s>& das Modell, welches von <u>Duc Anh Pham</u> verbessert wurde</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb2b2c",
   "metadata": {},
   "source": [
    "Bevor ich mit diesem Projekt angefangen habe, hab ich ein paar Tutorials bearbeitet. Was mir aufgefallen ist, ist das viele Leute irgendwelche Libaries nutzen, die die Ganze Arbeit übernehmen. Darunter auch pretrained-Models. <br />\n",
    "Eine Libary wurde häufig genutzt und ist sehr simple: Textblob. Dies hab ich in einem Youtube Video von <a href=\"https://www.youtube.com/watch?v=tXuvh5_Xyrw\">NeuralNine</a> gesehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7216e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "-0.8\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob #Textblob muss natürlich vorher runtergeladen werden. \n",
    "\n",
    "text = \"I love it\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "sentimentTextBlobPositive = blob.sentiment.polarity \n",
    "#Ich speicher das hier in einer Variable, um das unten mit meinen Ergebnissen zu vergleichen\n",
    "\n",
    "text = \"I hate it\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "sentimentTextBlobNegative = blob.sentiment.polarity\n",
    "#Ich speicher das hier in einer Variable, um das unten mit meinen Ergebnissen zu vergleichen\n",
    "\n",
    "print(sentimentTextBlobPositive)\n",
    "print(sentimentTextBlobNegative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab2b49",
   "metadata": {},
   "source": [
    "Für das Ganze werden vor die Keywords (\"hate\", \"love\")stärker verwendet und sogenannte Stopwords(\"I\", \"It\") weniger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c207cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "-0.8\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "text = \"love\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "sentimentTextBlobKeyLove = blob.sentiment.polarity \n",
    "#Ich speicher das hier in einer Variable, um das unten mit meinen Ergebnissen zu vergleichen\n",
    "text = \"hate\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "sentimentTextBlobKeyHate = blob.sentiment.polarity \n",
    "\n",
    "text = \"I it\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "sentimentTextBlobStop = blob.sentiment.polarity\n",
    "#Ich speicher das hier in einer Variable, um das unten mit meinen Ergebnissen zu vergleichen\n",
    "\n",
    "print(sentimentTextBlobKeyLove)\n",
    "print(sentimentTextBlobKeyHate)\n",
    "print(sentimentTextBlobStop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c336a",
   "metadata": {},
   "source": [
    "Ich könnte später einfach ein Stopword Datensatz importieren, doch wie man später sehen wird, hab ich das anders gelöst. Wörter die häufig vorkommen werden bei mir eine niedrigere Gewichtung haben, als Wörter die häufig vorkommen. Aber dazu später mehr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248d910",
   "metadata": {},
   "source": [
    "Jetzt wo man weiß, wohin es gehen soll, werde ich darauf hinarbeiten. <br />\n",
    "Als erstes importiere ich ein paar Libaries. Die Anzahl dieser soll möglichst gering bleibe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6dcf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # Für csv Dateien, damit ich mein Model trainieren kann\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json # Für json datei(meine Abspeicherungen)\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c16af",
   "metadata": {},
   "source": [
    "Zudem definiere ich mir ein paar Farben für die prints. Direkt danach ein Template für Fehlermeldungen<br />\n",
    "Gefunden auf <a href=\"https://stackoverflow.com/questions/287871/how-do-i-print-colored-text-to-the-terminal\">StackOverflow</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd30049",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRED = \"\\033[91m\"\n",
    "CORANGE = \"\\033[33m\"\n",
    "\n",
    "error = CRED +\"[Error]: \" + CORANGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc1e84",
   "metadata": {},
   "source": [
    "Felder/Arrays in Variablen zu speichern, die ich später generell nutzen kann ist auch ganz gut, um das immer erweitern zu können\n",
    "<ol>\n",
    "    <li>Satzzeichen</li>\n",
    "    <li>Negationen</li>\n",
    "    <li>Symbole etc.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d97736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "stop = [\",\", \"!\", \".\", \"?\", \":\", \"&\"]\n",
    "#2\n",
    "negation = [\"not\", \"isn't\", \"isnt\", \"doesn't\", \"doesnt\", \"dont\", \"don't\", \"wont\", \"won't\", \"werent\", \"weren't\", \"shouldnt\",\n",
    "           \"shouldn't\", \"didnt\", \"didn't\", \"arent\", \"aren't\", \"havent\", \"haven't\", \"hadnt\", \"hadn't\", \"can't\", \"cannot\", \n",
    "            \"aint\", \"ain't\"]\n",
    "for x in negation:\n",
    "    if \"'\" in x:\n",
    "        arr = x.split(\"'\")\n",
    "        negation.append(arr[0])\n",
    "        negation.append(arr[0] + \"´\" + arr[1])\n",
    "        negation.append(arr[0] + \"`\" + arr[1])\n",
    "\n",
    "#3\n",
    "signs = [\"\\\\\", \"\\\"\", \"/\", \"(\", \")\", \"{\", \"}\", \"<\", \">\", \"~\", \"'\", \"[*]\", \"[b]\", \"[u]\", \"+\", \"*\", \";\", \"-\", \"`\", \"´\", \"_\",\n",
    "         \"#\", \"\\\\t\", \"\\\\b\", \"\\t\", \"\\b\", \"%\", \"$\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"=\", \"^\", \"[\", \"]\", \n",
    "         \"\\u0010own\", \"\\u000b\\u000b\", \"\\u000b\", \"\\u000b\\u000b\", \"\\u000b\\u000b\", \"\\u000b\", \"\\u0002\", \"\\u0003\", \"\\u0004\", \n",
    "         \"\\u0005\", \"\\u0010\", \"\\u0013\", \"\\u0014\", \"\\u0015\", \"\\u0016\", \"\\u0018\", \"\\u0019\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a922d22",
   "metadata": {},
   "source": [
    "Nun ein paar erste Funktionen, die ich später fürs Preprocessing nutzen kann. \n",
    "<ol>\n",
    "    <li>Funktion, die in einem String bestimmte Buchstabensequenzen sucht und den selben String returnen, jedoch ohne Wörter mit den Buchstabensequenzen</li>\n",
    "    <li>Funktion, die in Arrays nach Values schaut, die nichts enthalten, und einen array returned ohne diese Values</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f101f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def deleteWordbySearch(sentence, search):\n",
    "    arr = sentence.split(\" \")\n",
    "    result = \"\"\n",
    "    for x in arr:\n",
    "        if search not in x:\n",
    "            result += x + \" \"\n",
    "    return result[:-1]\n",
    "\n",
    "#2\n",
    "def deleteWhitespacesinArray(arr = []):\n",
    "    result = []\n",
    "    for x in arr:\n",
    "        if x != \"\":\n",
    "            result.append(x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a1f44",
   "metadata": {},
   "source": [
    "Eine Idee, was ins Preprocessing gehört habe ich aus folgenden Quellen: <br />\n",
    "[Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. <b>Sentiment Analysis</b> of Twitter Data. In Proceedings of the Workshop on Language in Social Media (LSM 2011), pages 30–38, Portland, Oregon. Association for Computational Linguistics.]<br />\n",
    "[Gupta, Bhumika & Negi, Monika & Vishwakarma, Kanika & Rawat, Goldi & Badhani, Priyanka. (2017). <b>Study of Twitter Sentiment Analysis using Machine Learning Algorithms on Python</b>. International Journal of Computer Applications. 165. 29-34. 10.5120/ijca2017914022.] <br />\n",
    "<a href=\"https://www.analyticsvidhya.com/blog/2021/08/text-preprocessing-techniques-for-performing-sentiment-analysis/\">Text Preprocessing techniques for Performing Sentiment Analysis!</a>\n",
    "<br /><br />\n",
    "Andere Dinge sind mir nach testen des Systems an einem Datasets aufgefallen <br /> \n",
    "Dies kann das Preprocessing bereits:\n",
    "<ol>\n",
    "    <li>\n",
    "        Bestimmte Wörter werden gelöscht\n",
    "        <ul>\n",
    "            <li>URLs</li>\n",
    "            <li>Email-Adressen</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Eine Satzaufteilung</li>\n",
    "    <li>Negationen kennzeichnen</li>\n",
    "    <li>Wörter aufteilen</li>\n",
    "    <li>Löschen von verschiedenen Zeichen und Tags</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3825dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def pre_deleteWords(string):\n",
    "    string = deleteWordbySearch(string, \"@\")\n",
    "    string = deleteWordbySearch(string, \"http\")\n",
    "    \n",
    "    return string\n",
    "\n",
    "#2\n",
    "def pre_sentence_split(string):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    st = string\n",
    "    i = 0\n",
    "    hasStop = 0\n",
    "    while i < len(st):\n",
    "        if st[i] in stop:\n",
    "            hasStop = 1\n",
    "            thestop = st[i]\n",
    "            s = st.split(thestop, 1) # string.split(a, 1) 1 deutet an wie häufig gesplittet wird\n",
    "            result.append(s[0])\n",
    "            result.append(thestop)\n",
    "            n=1\n",
    "            st = \"\"\n",
    "            while n < len(s):\n",
    "                st += s[n]\n",
    "                n+=1\n",
    "                \n",
    "            i=0\n",
    "        else:\n",
    "            i+=1\n",
    "    result.append(st)\n",
    "    \n",
    "    return result\n",
    "#3\n",
    "def pre_negation(arr):\n",
    "    result = []\n",
    "    for x in arr:\n",
    "        b = 0\n",
    "        words = x.split(\" \")\n",
    "        for word in words:\n",
    "            if word in negation:\n",
    "                b = 1\n",
    "        if b == 1:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "        \n",
    "    return result\n",
    "\n",
    "#4\n",
    "def pre_tokenizer(string):\n",
    "    result = []\n",
    "    \n",
    "    arr = string.split(\" \")\n",
    "    \n",
    "    for word in arr:\n",
    "        result.append(word)\n",
    "    \n",
    "    return result\n",
    "#5\n",
    "def deleteSpecialTags(string):\n",
    "    \n",
    "    string = string.encode(\"ascii\", \"ignore\")\n",
    "    string = string.decode()\n",
    "    string = string.replace(\"\\n\", \".\")\n",
    "    \n",
    "    for x in signs:\n",
    "        string = string.replace(x, \" \")\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4fde3",
   "metadata": {},
   "source": [
    "Nun eine Funktion, die alle Preprocessing Funktionen vereint. Das Ganze hätte man auch in eine Große Funktion hineinschreiben können, jedoch soll dies der Übersicht dienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f681d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i am happy', ',', ' i am not happy']\n",
      "([['i', 'am', 'happy'], [','], ['i', 'am', 'not', 'happy']], [1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(string):\n",
    "    string = string.lower()\n",
    "    string = pre_deleteWords(string)\n",
    "    string = deleteSpecialTags(string)\n",
    "    \n",
    "    arr = pre_sentence_split(string)\n",
    "    \n",
    "    negations = pre_negation(arr)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    i = 0\n",
    "    for x in arr:\n",
    "        x = deleteWhitespacesinArray(pre_tokenizer(x))\n",
    "        result.append(x)\n",
    "    \n",
    "    return result, negations\n",
    "print(preprocessing(\"i am happy, i am not happy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ba328",
   "metadata": {},
   "source": [
    "Nach angewendeten Preprocessing soll das Ganze wie folgt aussehen:<br />\n",
    "<b>(</b>[<i>[Satz 1]</i>, <i>[Satzzeichen]</i>, <i>[Satz 2]</i>, <i>[Satzzeichen]</i>, <i>[Satz 3]</i>], [<i>Negation 1</i>, <i>Negation 2</i>, <i>Negation 3</i>, <i>Negation 4</i>, <i>Negation 5</i>]<b>)</b><br /><br />\n",
    "Jetzt braucht man ein Modell, welches Wörter mit einem Sentiment Wert verbindet. Hierzu erstelle ich die Klasse NeuronalNetwork. Der Zustand ist ein Wert zwischen -1 und 1. Hier nenne ich ihn Sentiment.<br />\n",
    "Diese beinhaltet die Methoden:\n",
    "<ol>\n",
    "    <li><b>__<u>init</u>__</b><br/>\n",
    "Zur Erstellung von diesem Objekt</li>\n",
    "    <li><b><u>setNeuron</u></b><br/>\n",
    "Setzt ein Wort mit einem Zustand zwischen -1 und 1 in Verbindung. Wörter können mit mehr als nur einen Zustand in Verbindung gebracht werden.</li>\n",
    "    <li><b><u>trainModel</u></b><br />\n",
    "Bekommt Sätze mittels eines Strings und einen Zustand. Diese Sätze werden durchs Preprocessing verarbeitet. Am Ende gibt es nur noch einzelne Wörter und Satzzeichen, siehe Preprocessing. Danach wird die Funktion setNeuron genutzt, um Wörtern einen neuen Zustand zu geben. Hier wird auch auf Negationen geachtet. \n",
    "    <li><b><u>getNeuron</u></b><br />\n",
    "Wird mithilfe eines Wortes aufgerufen. Es wird zurückgegeben ein Tupel aus dem Durchschnitt aller Werte und den Werten.</li>\n",
    "    <li><b><u>getRating</u></b><br />\n",
    "Hier wird ein Rating für Sätze ausgebildet. Es wird drauf geachtet, dass Wörter mit höheren/niedrigeren Werten mehr Gewicht haben, als eher niedrige. So sollen beispielsweise neutralere Wörter, wie \"I\", \"and\" etc weniger Bedeutung haben als \"hate\" </li>\n",
    "    <li><b><u>saveNeurons</u></b><br />\n",
    "Speichert die Wörter und Zustände in einer Datei\n",
    "    <li><b><u>getNeuronsfromJson</u></b><br />\n",
    "Holt die Wörter und Zustände aus einer JSON Datei</li>\n",
    "    <li><b><u>getHowManyWords</u></b><br />\n",
    "Gibt zurück wie viele Wörter schon gespeichert wurden\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfd52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronalNetwork():\n",
    "    neurons = {}\n",
    "    lenall = 0\n",
    "    name = \"\"\n",
    "    lenwords = 0\n",
    "    #1\n",
    "    def __init__(self, name:str):\n",
    "        self.words = {}\n",
    "        self.lenall = 0\n",
    "        self.name = name\n",
    "        self.lenwords = 0\n",
    "        #self.getNeuronsfromJson()\n",
    "    #2    \n",
    "    def setNeuron(self, word:str, sentiment:float):\n",
    "        if sentiment >= -1 and sentiment <= 1 and len(word.split(\" \")) == 1:\n",
    "            if len(word) > 0:\n",
    "                if word[0] in self.neurons:\n",
    "                    if word in self.neurons[word[0]]:\n",
    "                        if sentiment in self.neurons[word[0]][word]:\n",
    "                            self.neurons[word[0]][word][sentiment] += 1\n",
    "                        else:\n",
    "                            self.neurons[word[0]][word][sentiment] = 1\n",
    "                            self.lenwords +=1\n",
    "                    else:\n",
    "                        self.neurons[word[0]][word] = {}\n",
    "                        self.neurons[word[0]][word][sentiment] = 1\n",
    "                        self.lenwords +=1\n",
    "                else:\n",
    "                    self.neurons[word[0]] = {}\n",
    "                    self.neurons[word[0]][word] = {}\n",
    "                    self.neurons[word[0]][word][sentiment] = 1\n",
    "                    self.lenwords +=1\n",
    "            \n",
    "        else:\n",
    "            print(error + \"Sentiment must be below or equal 1 and above or equal -1 \\n\" +CRED +\"Error: \" + CORANGE +\"Error: It can only be one word.\")\n",
    "    #3    \n",
    "    def trainModel(self, string, sentiment):\n",
    "        arr = preprocessing(string)\n",
    "        #print(string)\n",
    "        #print(sentiment)\n",
    "        i = 0\n",
    "        self.lenall+=1\n",
    "        for x in arr[0]:\n",
    "            s = sentiment\n",
    "            result = x\n",
    "            if arr[1][i] == 0:\n",
    "                result = []\n",
    "                s = s * (-1)\n",
    "                for word in x:\n",
    "                    if len(word) > 0:\n",
    "                        if word not in negation:\n",
    "                            result.append(word)\n",
    "            for word in result:\n",
    "                self.setNeuron(word, s)\n",
    "            i+=1\n",
    "    #4\n",
    "    def getNeuron(self, word:str):\n",
    "        if word[0] in self.neurons:\n",
    "            if word in self.neurons[word[0]]:\n",
    "                result = 0\n",
    "                i = 0\n",
    "                for x in self.neurons[word[0]][word].keys():\n",
    "                    b = int(x)\n",
    "                    a = int(self.neurons[word[0]][word][b])\n",
    "                    result += x*a\n",
    "                    #print(a)\n",
    "                    i += int(a)\n",
    "                return result/i, i\n",
    "            else:\n",
    "                return 0, 0\n",
    "        else:\n",
    "            return 0, 0\n",
    "    #5\n",
    "    def getRating(self, string):\n",
    "        arr = preprocessing(string)\n",
    "        i = 0\n",
    "        sentiment = 0\n",
    "        a = 0\n",
    "        for x in arr[0]:\n",
    "            #print(x)\n",
    "            negation = 1\n",
    "            if arr[1][i] == 0:\n",
    "                negation = -1\n",
    "            for word in x:\n",
    "                a += 1\n",
    "                c = 0.5\n",
    "                d = self.getNeuron(word)[1]\n",
    "                if d/self.lenall >= c:\n",
    "                    sentiment += 0.5 * self.getNeuron(word)[0] * negation\n",
    "                    a += 0.5\n",
    "                while c > 0.001: #Je weniger ein Wort vorkommt, desto mehr Wert legt man auf dieses Wort\n",
    "                    if d/self.lenall < c:\n",
    "                        sentiment+=self.getNeuron(word)[0] * negation\n",
    "                        a+=1\n",
    "                    else:\n",
    "                        break\n",
    "                    c/=2\n",
    "            i+=1\n",
    "        if a == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return sentiment / a\n",
    "    #6\n",
    "    def saveNeurons(self):\n",
    "        jsonString = self.neurons\n",
    "        config = {}\n",
    "        jsonString[\"lenall\"] = self.lenall\n",
    "        jsonString[\"lenwords\"] = self.lenwords\n",
    "        json.dump(jsonString,open(self.name+'.json','w'),indent=4,sort_keys=True)\n",
    "    #7    \n",
    "    def getNeuronsfromJson(self):\n",
    "        f = open(self.name+'.json')\n",
    "        self.neurons = json.load(f)\n",
    "        self.lenall = self.neurons[\"lenall\"]\n",
    "        self.lenwords = self.neurons[\"lenwords\"]\n",
    "        print(self.neurons)\n",
    "        #print(self.neurons)\n",
    "    #8\n",
    "    def getHowManyWords(self):\n",
    "        return self.lenwords\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6d220",
   "metadata": {},
   "source": [
    "Hier mache ich eine Funktion, die fürs Training wichtig ist. So haben die beiden Datensätze entweder ein Rating von 1-5 oder ein Sentiment von \"positive\", \"negative\" oder \"neutral\". Diese müssen einen passenden Zustandswert bekommen, der zwischen -1 und +1 liegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4966192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(i:float) -> float:\n",
    "    result = 0\n",
    "    if(i == 5):\n",
    "        result = 1\n",
    "    elif(i == 4):\n",
    "        result = 0.5\n",
    "    elif(i == 3):\n",
    "        result = 0\n",
    "    elif(i == 2):\n",
    "        result = -0.5\n",
    "    elif(i == 1):\n",
    "        result = -1\n",
    "    elif(str(i).lower() == \"positive\"):\n",
    "        result = 1\n",
    "    elif(str(i).lower() == \"neutral\"):\n",
    "        result = 0\n",
    "    elif(str(i).lower() == \"negative\"):\n",
    "        result = -1\n",
    "    elif(str(i).lower() == \"true\"):\n",
    "        result = 1\n",
    "    elif(str(i).lower() == \"false\"):\n",
    "        result = -1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211ea72",
   "metadata": {},
   "source": [
    "Evaluationsansätze: <br />\n",
    "<a href=\"https://www.jeremyjordan.me/evaluating-a-machine-learning-model/\">Evaluating a machine learning model</a>\n",
    "- Datensätze nehmen: einer eher negativ, einer neutral,  einer eher positiv\n",
    "    - Jeweils mit einem anderen Datensatz dann auswerten, wie viele macht er richtig, wie schneidet er im Vergleich <s>zu Ducs und</s> zu einem anderen ab?\n",
    "    Kurzes Bild wie das aussehen kann:\n",
    "    <img src=\"https://www.jeremyjordan.me/content/images/2017/07/Screen-Shot-2017-07-21-at-9.57.38-AM.png\" width=500px height= 500px>\n",
    "- Lernkurve, alle 50k Datensätze wird aus einem Datensatz was ausgewertet, wann bekommt man brauchbare Ergebnisse? Wie sieht es im Vergleich zu anderen Modellen aus?\n",
    "- Um das schön auswerten zu können, braucht es Werte, die man miteinander automatisch vergleichen kann. Diese kann man wie folgt ausrechnen (Quelle ist oben verlinkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63072c05",
   "metadata": {},
   "source": [
    "\"<b>Accuracy</b> is defined as the percentage of correct predictions for the test data. It can be calculated easily by dividing the number of correct predictions by the number of total predictions.\" (<a href=\"https://www.jeremyjordan.me/evaluating-a-machine-learning-model/\">Quelle 23.11.2022</a>)<br />\n",
    "$ accuracy = \\frac{correct predictions}{all predictions} $<br /><br />\n",
    "\"<b>Precision</b> is defined as the fraction of relevant examples (true positives) among all of the examples which were predicted to belong in a certain class. \"(<a href=\"https://www.jeremyjordan.me/evaluating-a-machine-learning-model/\">Quelle 23.11.2022</a>) <br />\n",
    "$ precision = \\frac{true positives}{true positives + false positives} $ <br /><br />\n",
    "<br />\n",
    "\"<b>Recall</b> is defined as the fraction of examples which were predicted to belong to a class with respect to all of the examples that truly belong in the class.\"(<a href=\"https://www.jeremyjordan.me/evaluating-a-machine-learning-model/\">Quelle 23.11.2022</a>) <br />\n",
    "$ recall = \\frac{true positives}{true positives + false negatives} $ <br /><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5883a",
   "metadata": {},
   "source": [
    "Auf der Website wird beschrieben, wie man einen Wert ausrechnen kann die man als Endnote bezeichnen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a90b3d",
   "metadata": {},
   "source": [
    "$ F_\\beta = (1+ \\beta^2) \\frac{precision * recall}{(\\beta^2*precision)+recall} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fda8e",
   "metadata": {},
   "source": [
    "Deshalb eine Methode, die aus den angegebenen Zahlen accuracy, precision, recall und den $ F_\\beta $ Wert ausgibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980f8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(truepositive, truenegative, falsepositive, falsenegative, beta=1):\n",
    "    accuracy = (truenegative + truepositive)/(truenegative + truepositive + falsenegative + falsepositive)\n",
    "    \n",
    "    precision = truepositive/(truepositive+falsepositive)\n",
    "    \n",
    "    recall = truepositive/(truepositive+falsenegative)\n",
    "\n",
    "    f = (1+beta**2) * (((precision*beta**2)*recall)/(precision+recall))\n",
    "    \n",
    "    return f, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae41d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(nn, zeilen=10000):\n",
    "    with open('test.csv', encoding='utf-8') as csvdatei:\n",
    "        csv_reader_object = csv.reader(csvdatei)\n",
    "        zeile = 1;\n",
    "        truepositive = 0\n",
    "        truenegative = 0\n",
    "        falsepositive = 0\n",
    "        falsenegative = 0\n",
    "\n",
    "        for row in csv_reader_object:\n",
    "            if zeile < zeilen:\n",
    "                rate = 0\n",
    "                if int(row[0]) == 2:\n",
    "                    rate = 1\n",
    "                elif int(row[0]) == 1:\n",
    "                    rate = -1\n",
    "                rating = nn.getRating(row[1] + row[2])\n",
    "                if rating < 0:\n",
    "                    rating = -1\n",
    "                else:\n",
    "                    rating = 1\n",
    "                if rate == rating:\n",
    "                    if rate == 1:\n",
    "                        truepositive+=1\n",
    "                    elif rate == -1:\n",
    "                        truenegative += 1\n",
    "                else: \n",
    "                    if rate == 1:\n",
    "                        falsepositive+=1\n",
    "                    elif rate == -1:\n",
    "                        falsenegative += 1\n",
    "                zeile +=1\n",
    "        return evaluate(truepositive, truenegative, falsepositive, falsenegative), truepositive, truenegative, falsepositive, falsenegative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d550b9",
   "metadata": {},
   "source": [
    "Beta wird bei der Bewertung 1 sein, damit eine gleiche Gewichtung herrscht\n",
    "\n",
    "Zeit rauskopiert aus <a href=\"https://gertingold.github.io/pythonnawi/profiling.html\">Laufzeituntersuchungen</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac301ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeile: 50000 Insgesamt: 50000\n",
      "((0.7938363443145589, 0.7671767176717672, 0.8747072599531616, 0.7266536964980544), 4482, 3189, 642, 1686)\n",
      "Zeile: 100000 Insgesamt: 100000\n",
      "((0.8030012214273252, 0.7741774177417742, 0.8981264637002342, 0.7260965604291575), 4602, 3139, 522, 1736)\n",
      "Zeile: 150000 Insgesamt: 150000\n",
      "((0.8099467140319715, 0.785978597859786, 0.8899297423887588, 0.7431551499348109), 4560, 3299, 564, 1576)\n",
      "Zeile: 200000 Insgesamt: 200000\n",
      "((0.8122044785440271, 0.7894789478947895, 0.8883684621389539, 0.7480690221857026), 4552, 3342, 572, 1533)\n",
      "Zeile: 250000 Insgesamt: 250000\n",
      "((0.8070949523473351, 0.7813781378137814, 0.8924668227946917, 0.7366301546391752), 4573, 3240, 551, 1635)\n",
      "Zeile: 300000 Insgesamt: 300000\n",
      "((0.8069276309976142, 0.7814781478147815, 0.8911007025761124, 0.7372840303568545), 4566, 3248, 558, 1627)\n",
      "Zeile: 350000 Insgesamt: 350000\n",
      "((0.8064630054741303, 0.7807780778077807, 0.8912958626073381, 0.736375362786198), 4567, 3240, 557, 1635)\n",
      "Zeile: 400000 Insgesamt: 400000\n",
      "((0.80984538830638, 0.785978597859786, 0.889344262295082, 0.7433931484502447), 4557, 3302, 567, 1573)\n",
      "Zeile: 450000 Insgesamt: 450000\n",
      "((0.8107149192833065, 0.7865786578657866, 0.8918813427010148, 0.7430894308943089), 4570, 3295, 554, 1580)\n",
      "Zeile: 500000 Insgesamt: 500000\n",
      "((0.8090265486725663, 0.7841784178417842, 0.8920765027322405, 0.7401230569948186), 4571, 3270, 553, 1605)\n",
      "Zeile: 550000 Insgesamt: 550000\n",
      "((0.8108634111818825, 0.7861786178617862, 0.8944184231069477, 0.7415857605177993), 4583, 3278, 541, 1597)\n",
      "Zeile: 600000 Insgesamt: 600000\n",
      "((0.8111356606274857, 0.7862786278627862, 0.8955893832943014, 0.7412372799224681), 4589, 3273, 535, 1602)\n",
      "Zeile: 650000 Insgesamt: 650000\n",
      "((0.8125606421451883, 0.7874787478747874, 0.8989071038251366, 0.7413487848060518), 4606, 3268, 518, 1607)\n",
      "Zeile: 700000 Insgesamt: 700000\n",
      "((0.8121041520056299, 0.7863786378637864, 0.9008587041373927, 0.7392696989109545), 4616, 3247, 508, 1628)\n",
      "Zeile: 750000 Insgesamt: 750000\n",
      "((0.813945278022948, 0.7891789178917892, 0.8998829039812647, 0.7429906542056075), 4611, 3280, 513, 1595)\n",
      "Zeile: 800000 Insgesamt: 800000\n",
      "((0.8143236074270557, 0.78997899789979, 0.8987119437939111, 0.7444228903976722), 4605, 3294, 519, 1581)\n",
      "Zeile: 850000 Insgesamt: 850000\n",
      "((0.8147821485270771, 0.78997899789979, 0.9014441842310694, 0.7433215320244609), 4619, 3280, 505, 1595)\n",
      "Zeile: 900000 Insgesamt: 900000\n",
      "((0.8155408388520972, 0.7910791079107911, 0.9012490241998439, 0.7447185937751976), 4618, 3292, 506, 1583)\n",
      "Zeile: 950000 Insgesamt: 950000\n",
      "((0.8145736161225029, 0.7892789278927893, 0.9032006245120999, 0.7417855425548966), 4628, 3264, 496, 1611)\n",
      "Zeile: 1000000 Insgesamt: 1000000\n",
      "((0.8147626178102704, 0.7896789678967897, 0.902615144418423, 0.7424947824690962), 4625, 3271, 499, 1604)\n",
      "Zeile: 1050000 Insgesamt: 1050000\n",
      "((0.8146062472503299, 0.7892789278927893, 0.9033957845433255, 0.7417080596058324), 4629, 3263, 495, 1612)\n",
      "Zeile: 1100000 Insgesamt: 1100000\n",
      "((0.8163013819206056, 0.7912791279127913, 0.9049570647931303, 0.7434664101330768), 4637, 3275, 487, 1600)\n",
      "Zeile: 1150000 Insgesamt: 1150000\n",
      "((0.8168939727232732, 0.7918791879187919, 0.9059328649492584, 0.7437910591251402), 4642, 3276, 482, 1599)\n",
      "Zeile: 1200000 Insgesamt: 1200000\n",
      "((0.8167400881057268, 0.791979197919792, 0.9045667447306791, 0.7444587214905236), 4635, 3284, 489, 1591)\n",
      "Zeile: 1250000 Insgesamt: 1250000\n",
      "((0.8165169924282444, 0.7915791579157916, 0.9049570647931303, 0.7438241899262111), 4637, 3278, 487, 1597)\n",
      "Zeile: 1300000 Insgesamt: 1300000\n",
      "((0.8170355347852921, 0.7924792479247925, 0.9041764246682279, 0.7452147337944346), 4633, 3291, 491, 1584)\n",
      "Zeile: 1350000 Insgesamt: 1350000\n",
      "((0.8179973533303926, 0.7936793679367937, 0.9047619047619048, 0.7464176461117372), 4636, 3300, 488, 1575)\n",
      "Zeile: 1400000 Insgesamt: 1400000\n",
      "((0.8172176065052147, 0.7931793179317932, 0.9022248243559718, 0.7468497576736672), 4623, 3308, 501, 1567)\n",
      "Zeile: 1450000 Insgesamt: 1450000\n",
      "((0.8194579323739736, 0.7954795479547955, 0.9057377049180327, 0.7481863614380139), 4641, 3313, 483, 1562)\n",
      "Zeile: 1500000 Insgesamt: 1500000\n",
      "((0.8184147742334541, 0.7944794479447945, 0.9037861046057767, 0.7477797513321492), 4631, 3313, 493, 1562)\n",
      "Zeile: 1550000 Insgesamt: 1550000\n",
      "((0.8179489444395371, 0.7938793879387939, 0.9035909445745511, 0.7471357108278199), 4630, 3308, 494, 1567)\n",
      "Zeile: 1600000 Insgesamt: 1600000\n",
      "((0.8185437494470494, 0.7948794879487949, 0.9028103044496487, 0.7486648324971679), 4626, 3322, 498, 1553)\n",
      "Zeile: 1650000 Insgesamt: 1650000\n",
      "((0.8174988952717632, 0.7934793479347935, 0.902615144418423, 0.7470521725084801), 4625, 3309, 499, 1566)\n",
      "Zeile: 1700000 Insgesamt: 1700000\n",
      "((0.818415227976981, 0.7948794879487949, 0.9020296643247463, 0.7489871981850591), 4622, 3326, 502, 1549)\n",
      "Zeile: 1750000 Insgesamt: 1750000\n",
      "((0.8189784898645658, 0.7954795479547955, 0.9028103044496487, 0.7493925157945893), 4626, 3328, 498, 1547)\n",
      "Zeile: 1800000 Insgesamt: 1800000\n",
      "((0.8186647777581016, 0.7951795179517952, 0.9022248243559718, 0.7492706645056726), 4623, 3328, 501, 1547)\n",
      "Zeile: 1850000 Insgesamt: 1850000\n",
      "((0.8189800443458981, 0.7958795879587959, 0.9010538641686182, 0.750609656966347), 4617, 3341, 507, 1534)\n",
      "Zeile: 1900000 Insgesamt: 1900000\n",
      "((0.8191150442477877, 0.7955795579557956, 0.9032006245120999, 0.7493523316062176), 4628, 3327, 496, 1548)\n",
      "Zeile: 1950000 Insgesamt: 1950000\n",
      "((0.8191470536188284, 0.7955795579557956, 0.9033957845433255, 0.7492716089349304), 4629, 3326, 495, 1549)\n",
      "Zeile: 2000000 Insgesamt: 2000000\n",
      "((0.8192515261435018, 0.7956795679567957, 0.9035909445745511, 0.749312186437935), 4630, 3326, 494, 1549)\n",
      "Zeile: 2050000 Insgesamt: 2050000\n",
      "((0.8189449500751083, 0.7950795079507951, 0.9043715846994536, 0.7482641692233166), 4634, 3316, 490, 1559)\n",
      "Zeile: 2100000 Insgesamt: 2100000\n",
      "((0.8174343559366987, 0.7934793479347935, 0.9022248243559718, 0.7472118959107806), 4623, 3311, 501, 1564)\n",
      "Zeile: 2150000 Insgesamt: 2150000\n",
      "((0.8178287731685792, 0.7935793579357936, 0.9041764246682279, 0.7465356106993233), 4633, 3302, 491, 1573)\n",
      "Zeile: 2200000 Insgesamt: 2200000\n",
      "((0.8164707961473887, 0.7922792279227923, 0.9016393442622951, 0.7460035523978685), 4620, 3302, 504, 1573)\n",
      "Zeile: 2250000 Insgesamt: 2250000\n",
      "((0.8163914157025524, 0.7920792079207921, 0.9020296643247463, 0.7456041296983384), 4622, 3298, 502, 1577)\n",
      "Zeile: 2300000 Insgesamt: 2300000\n",
      "((0.8163049232398094, 0.7917791779177917, 0.9028103044496487, 0.744927536231884), 4626, 3291, 498, 1584)\n",
      "Zeile: 2350000 Insgesamt: 2350000\n",
      "((0.8170753219262658, 0.7925792579257925, 0.9039812646370023, 0.7454135822336659), 4632, 3293, 492, 1582)\n",
      "Zeile: 2400000 Insgesamt: 2400000\n",
      "((0.8171453822359699, 0.7930793079307931, 0.9022248243559718, 0.7467291229203683), 4623, 3307, 501, 1568)\n",
      "Zeile: 2450000 Insgesamt: 2450000\n",
      "((0.8174097664543524, 0.7935793579357936, 0.9016393442622951, 0.7475728155339806), 4620, 3315, 504, 1560)\n",
      "Zeile: 2500000 Insgesamt: 2500000\n",
      "((0.8178280863105767, 0.793979397939794, 0.9024199843871975, 0.7477360931435963), 4624, 3315, 500, 1560)\n",
      "Zeile: 2550000 Insgesamt: 2550000\n",
      "((0.817000971989043, 0.7928792879287929, 0.9022248243559718, 0.746487970289036), 4623, 3305, 501, 1570)\n",
      "Zeile: 2600000 Insgesamt: 2600000\n",
      "((0.8174420661595613, 0.7935793579357936, 0.9018345042935206, 0.7474927208023293), 4621, 3314, 503, 1561)\n",
      "Zeile: 2650000 Insgesamt: 2650000\n",
      "((0.8168864501283299, 0.7930793079307931, 0.900663544106167, 0.7473684210526316), 4615, 3315, 509, 1560)\n",
      "Zeile: 2700000 Insgesamt: 2700000\n",
      "((0.8178681999115435, 0.7940794079407941, 0.9022248243559718, 0.7479372269859246), 4623, 3317, 501, 1558)\n",
      "Zeile: 2750000 Insgesamt: 2750000\n",
      "((0.8181898610988233, 0.7944794479447945, 0.9024199843871975, 0.7483411555267843), 4624, 3320, 500, 1555)\n",
      "Zeile: 2800000 Insgesamt: 2800000\n",
      "((0.8180371352785145, 0.7941794179417941, 0.9028103044496487, 0.7478176527643065), 4626, 3315, 498, 1560)\n",
      "Zeile: 2850000 Insgesamt: 2850000\n",
      "((0.8182139699381079, 0.7943794379437944, 0.9030054644808743, 0.7479793081150986), 4627, 3316, 497, 1559)\n",
      "Zeile: 2900000 Insgesamt: 2900000\n",
      "((0.8177966101694915, 0.7935793579357936, 0.9039812646370023, 0.746615087040619), 4632, 3303, 492, 1572)\n",
      "Zeile: 2950000 Insgesamt: 2950000\n",
      "((0.8173713478683026, 0.7930793079307931, 0.9035909445745511, 0.7461724415793715), 4630, 3300, 494, 1575)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeile: 3000000 Insgesamt: 3000000\n",
      "((0.8175156705217621, 0.7932793279327933, 0.9035909445745511, 0.746413025955183), 4630, 3302, 494, 1573)\n",
      "Zeile: 3050000 Insgesamt: 3050000\n",
      "((0.8174035830906362, 0.7930793079307931, 0.9037861046057767, 0.746093120670211), 4631, 3299, 493, 1576)\n",
      "Zeile: 3100000 Insgesamt: 3100000\n",
      "((0.8180132450331126, 0.7938793879387939, 0.9039812646370023, 0.7469762941461054), 4632, 3306, 492, 1569)\n",
      "Zeile: 3150000 Insgesamt: 3150000\n",
      "((0.8179410206604273, 0.7937793779377937, 0.9039812646370023, 0.746855852950661), 4632, 3305, 492, 1570)\n",
      "Zeile: 3200000 Insgesamt: 3200000\n",
      "((0.8185832891715245, 0.7945794579457945, 0.9043715846994536, 0.7476605356566635), 4634, 3311, 490, 1564)\n",
      "Zeile: 3250000 Insgesamt: 3250000\n",
      "((0.8187516553368059, 0.7946794679467947, 0.9049570647931303, 0.7475415121715299), 4637, 3309, 487, 1566)\n",
      "Zeile: 3300000 Insgesamt: 3300000\n",
      "((0.8182861177301209, 0.7940794079407941, 0.9047619047619048, 0.7468986628000645), 4636, 3304, 488, 1571)\n",
      "Zeile: 3350000 Insgesamt: 3350000\n",
      "((0.8187919463087248, 0.7947794779477948, 0.9047619047619048, 0.747741935483871), 4636, 3311, 488, 1564)\n",
      "Zeile: 3400000 Insgesamt: 3400000\n",
      "((0.8189282245960978, 0.7948794879487949, 0.905152224824356, 0.7477027244881509), 4638, 3310, 486, 1565)\n",
      "Zeile: 3450000 Insgesamt: 3450000\n",
      "((0.8189921454417086, 0.7948794879487949, 0.9055425448868072, 0.7475430965039471), 4640, 3308, 484, 1567)\n",
      "Zeile: 3500000 Insgesamt: 3500000\n",
      "((0.8189282245960978, 0.7948794879487949, 0.905152224824356, 0.7477027244881509), 4638, 3310, 486, 1565)\n",
      "Zeile: 3550000 Insgesamt: 3550000\n",
      "((0.8187516553368059, 0.7946794679467947, 0.9049570647931303, 0.7475415121715299), 4637, 3309, 487, 1566)\n",
      "Zeile: 3600000 Insgesamt: 3600000\n",
      "((0.8184066419360537, 0.7943794379437944, 0.9041764246682279, 0.7474991932881575), 4633, 3310, 491, 1565)\n",
      "3600002\n"
     ]
    }
   ],
   "source": [
    "nn = NeuronalNetwork(\"6\")\n",
    "zeil = 0\n",
    "\n",
    "learningcurve = []\n",
    "start = time.time()\n",
    "with open('train.csv', encoding='utf-8') as csvdatei:\n",
    "    csv_reader_object = csv.reader(csvdatei)\n",
    "    zeile = 1;\n",
    "    gespeichert = 0\n",
    "    for row in csv_reader_object:\n",
    "        if zeile > 1:\n",
    "            rate = 0\n",
    "            if int(row[0]) == 2:\n",
    "                rate = 1\n",
    "            elif int(row[0]) == 1:\n",
    "                rate = -1\n",
    "            #print(rate)\n",
    "            nn.trainModel(row[1], rate)\n",
    "            nn.trainModel(row[2], rate)\n",
    "        zeil += 1\n",
    "        zeile +=1\n",
    "        if zeil % 50000 == 0 and zeil != 0:\n",
    "            print(\"Zeile: \" + str(zeile-1) + \" Insgesamt: \" + str(zeil))\n",
    "            learning = testing(nn)\n",
    "            print(learning)\n",
    "            learningcurve.append(learning)\n",
    "            nn.saveNeurons()\n",
    "    print(zeile)\n",
    "ende = time.time()\n",
    "timetrainwithcurve = '{:5.3f}s'.format(ende-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3d110",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "z = 0\n",
    "for y in learningcurve:\n",
    "    z+=50\n",
    "    x.append(z)\n",
    "    \n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "f = []\n",
    "\n",
    "for a in range(len(learningcurve)):\n",
    "    f.append(learningcurve[a][0])\n",
    "    accuracy.append(learningcurve[a][1])\n",
    "    recall.append(learningcurve[a][3])\n",
    "    precision.append(learningcurve[a][2])\n",
    "plt.plot(x, f, label=\"f\")\n",
    "plt.plot(x, accuracy, label=\"Accuracy\")\n",
    "plt.plot(x, precision, label=\"Precision\")\n",
    "plt.plot(x, recall, label=\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Trainierte Daten in 10.000\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Time: \" + str(timetrainwithcurve))\n",
    "\n",
    "print(\"Accuracy: \" + str(learningcurve[len(learningcurve)-1][1]))\n",
    "print(\"Precision: \" + str(learningcurve[len(learningcurve)-1][2]))\n",
    "print(\"Recall: \" + str(learningcurve[len(learningcurve)-1][3]))\n",
    "print(\"F: \" + str(learningcurve[len(learningcurve)-1][0]))\n",
    "\n",
    "learning = testing(nn, 400000)\n",
    "learningcurve.append(learning)\n",
    "print(\"\\n Endresultat: \")\n",
    "print(\"Accuracy: \" + str(learningcurve[len(learningcurve)-1][1]))\n",
    "print(\"Precision: \" + str(learningcurve[len(learningcurve)-1][2]))\n",
    "print(\"Recall: \" + str(learningcurve[len(learningcurve)-1][3]))\n",
    "print(\"F: \" + str(learningcurve[len(learningcurve)-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d7c7d",
   "metadata": {},
   "source": [
    "#### Randnotiz an mich\n",
    "```python\n",
    "import gzip, zip\n",
    "with gzip.open(\"meineDatei.txt.gz\") as f:\n",
    "```\n",
    "\n",
    "Finale Präsentation:\n",
    "- Intro, was wird gemacht\n",
    "- Struktur, Subthema\n",
    "- Evaluation\n",
    "- Was sollte man aus Grafik mitnehmen drauf schreiben\n",
    "- Fazit, Ausblick? Was  hat geklappt, was nicht\n",
    "- ca. 15 bis 20 Minuten\n",
    "\n",
    "Code Github<br />\n",
    "dazu readme-Datei mit bspw. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd98f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
